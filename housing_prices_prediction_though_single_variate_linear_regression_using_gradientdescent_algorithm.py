# -*- coding: utf-8 -*-
"""Housing_Prices_Prediction_though_Single_Variate_Linear_Regression_using GradientDescent_Algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qz4bPUGnK-Zg7YZAJ52JnpbTQiB-1EYt
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random

dataset = pd.read_csv("sample_data/california_housing_train.csv")

dataset

dataset.describe()

dataset.columns

dataset.corr()

feature = dataset['median_income']
target_var = dataset['median_house_value']

"""**y = mx + c**

     where m = slope (or, weight = W)
           c = intercept (or, bias = b)
           x = feature
           y = predicted value of target_var
           
**e = mean {(y - t)^2}**

     where y = y(p){mpg predicted} 
           t = y(d) {mpg from dataset given i.e., target value} 
           
***Note:*** The grapah of the error function is convex. So, we can apply Gradient Descent Algo to get the minimum error
           
___________________________________________________________________________________________________

## Gradient Descent Algorithm (*Geometric Intuition*):
It is an iterative optimization algo with update eqn: x(i) = x(i-1) - r* {{∂f(x)/∂x}| @ x=x(i-1)}


Now in ***Linear Regression***, since we've to to minimize slope and intercept to minimize the error (or cost, or loss) function; we use: 

**m = m - {r*(∂(e)/∂(m))**

     where ∂(e)/∂(m)= ∂(mean((y-t)^2))/∂(m) 
                     = ∂(mean(mx+c-t)^2))/∂(m) 
                     = 2*mean(mx+c-t)* {∂(mx)/∂(m) + ∂(c-t)/∂(m)} 
                     = 2*mean(mx+c-t)* {x + 0} 
                     = 2*mean(mx+c-t)* (x) 
                     
 **c = c -{r*(∂(e)/∂(c))}**

     where ∂(e)/∂(c) = ∂(mean((y-t)^2))/∂(c) 
                     = ∂(mean(mx+c-t)^2))/∂(c) 
                     = 2*mean(mx+c-t)* {∂(mx)/∂(c)+∂(c)/∂(c)-∂(t)/∂(c)} 
                     = 2*mean(mx+c-t)* {0 + 1 -0} 
                     = 2*mean(mx+c-t)
                     
**e =  mean {(y-t)^2**

         if y = t, then e(min) = 0
         if y = 0, then e(max) = mean(t^2)
         
**poe (i.e., %_of_error) = {current error / {(e(max))^2} } * 100**

             = {current error / mean(t^2)} * 100 

             = {current error / mean(target^2)} * 100 

          [Note: this formual is for prediction, not classification]
          
**poa (i.e., %_of_accuracy) = 100 - poe**
"""

def line(m,x,c):
  return m*x+c

def error(m,x,c,t):
  return np.mean((line(m,x,c) - t)**2)

def derivative_slope(m,x,c,t):
  return 2*np.mean((line(m,x,c) - t)*x)

def derivative_intercept(m,x,c,t):
  return 2*np.mean((line(m,x,c) - t))

def accuracy_prediction(current_error,t):
  return 100 - ((current_error/np.mean(t**2))*100)

m = random.random()
c = random.random()
cost = []
iterations = 100
learning_rate = 0.001
for i in range(0,iterations):
  m = m - learning_rate * derivative_slope(m,feature,c,target_var)
  c = c - learning_rate * derivative_intercept(m,feature,c,target_var)
  
  cost.append(error(m,feature,c,target_var))

print("Your Prediction Accuracy: ", accuracy_prediction(error(m,feature,c,target_var),target_var),"%")
plt.plot(cost)
plt.xlabel("number of iterations")
plt.ylabel("error")
plt.title("learning_rate=0.001")
plt.show()

plt.scatter(feature,target_var)
predicted_answers = line(m,feature,c)
plt.scatter(feature, predicted_answers)
plt.xlabel("median_income")
plt.ylabel("median_house_value")
plt.show()

m = random.random()
c = random.random()
cost = []
iterations = 950
learning_rate = 0.001
for i in range(0,iterations):
  m = m - learning_rate * derivative_slope(m,feature,c,target_var)
  c = c - learning_rate * derivative_intercept(m,feature,c,target_var)
  
  cost.append(error(m,feature,c,target_var))

print("Your Prediction Accuracy: ", accuracy_prediction(error(m,feature,c,target_var),target_var),"%")
plt.plot(cost)
plt.xlabel("number of iterations")
plt.ylabel("error")
plt.title("learning_rate=0.000001")
plt.show()

plt.scatter(feature,target_var)
predicted_answers = line(m,feature,c)
plt.scatter(feature, predicted_answers)
plt.xlabel("median_income")
plt.ylabel("median_house_value")
plt.show()

m = random.random()
c = random.random()
cost = []
iterations = 100
learning_rate = 0.0001
for i in range(0,iterations):
  m = m - learning_rate * derivative_slope(m,feature,c,target_var)
  c = c - learning_rate * derivative_intercept(m,feature,c,target_var)
  
  cost.append(error(m,feature,c,target_var))

print("Your Prediction Accuracy: ", accuracy_prediction(error(m,feature,c,target_var),target_var),"%")
plt.plot(cost)
plt.xlabel("number of iterations")
plt.ylabel("error")
plt.title("learning_rate=0.000001")
plt.show()

predicted_answers = line(m,feature,c)
plt.scatter(feature,target_var)
plt.scatter(feature, predicted_answers)
plt.show()